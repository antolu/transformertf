# Tune configuration for LSTM hyperparameter optimization
# This file contains the base model configuration and search space

# Base configuration - the actual model/data/trainer setup
base_config:
  seed_everything: true
  trainer:
    accelerator: auto
    strategy: auto
    devices: auto
    num_nodes: 1
    precision: null
    max_epochs: 500
    check_val_every_n_epoch: 1
    gradient_clip_val: 1.0
    use_distributed_sampler: false
    callbacks:
      - class_path: lightning.pytorch.callbacks.LearningRateMonitor
        init_args:
          logging_interval: epoch
  ckpt_path: null
  optimizer:
    class_path: torch.optim.SGD
    init_args:
      lr: 0.001  # This will be overridden by search_space
      momentum: 0.9
      weight_decay: 1e-4
  model:
    class_path: transformertf.models.lstm.LSTM
    init_args:
      num_features: 1
      num_layers: 3  # This will be overridden by search_space
      d_model: 300  # This will be overridden by search_space
      dropout: 0.2
      criterion:
        class_path: transformertf.nn.QuantileLoss
        init_args:
          quantiles: [0.25, 0.5, 0.75]  # This will be overridden by search_space
      log_grad_norm: false
  data:
    class_path: transformertf.data.TimeSeriesDataModule
    init_args:
      known_covariates:
        - "I_meas_A_medfilt"
      target_covariate: "B_meas_T_medfilt"
      train_df_paths:
        - "~/cernbox/hysteresis/dipole/datasets/train/SPS-BTRAIN-20231102-101712---20231102-102616_phys+lhcfill_zero_precycle_preprocessed.parquet"
        - "~/cernbox/hysteresis/dipole/datasets/train/SPS-BTRAIN-20231102-103421---20231102-104342_phys+lhcfill_md1_precycle_preprocessed.parquet"
        - "~/cernbox/hysteresis/dipole/datasets/train/SPS-BTRAIN-20231102-105113---20231102-114543_funky_preprocessed.parquet"
        - "~/cernbox/hysteresis/dipole/datasets/train/SPS-BTRAIN-20240314-130008---20240314-130555_bc_sftpro_lhcpilot_md_md1_preprocessed.parquet"
        - "~/cernbox/hysteresis/dipole/datasets/train/SPS-BTRAIN-20240318-080009---20240318-080549_bc_lhc_md_md1_preprocessed.parquet"
      val_df_paths:
        - "~/cernbox/hysteresis/dipole/datasets/val/SPS-BTRAIN-20231102-114546---20231102-115239_post_funky_preprocessed.parquet"
        - "~/cernbox/hysteresis/dipole/datasets/val/SPS-BTRAIN-20240328-160004---20240328-160821_DYNECO_preprocessed.parquet"
      normalize: true
      seq_len: 300  # This will be overridden by search_space
      min_seq_len: null
      randomize_seq_len: false
      stride: 1
      downsample: 40  # This will be overridden by search_space
      downsample_method: interval
      target_depends_on: "I_meas_A_medfilt"
      extra_transforms:
        B_meas_T_medfilt:
          - class_path: transformertf.data.transform.DiscreteFunctionTransform
            init_args:
              x: "~/cernbox/hysteresis/calibration_fn/SPS_MB_I2B_CALIBRATION_FN_v4.csv"
      batch_size: 512
      num_workers: 4
      dtype: float32
      distributed_sampler: false

# Search space - which parameters to tune and their ranges
search_space:
  model.init_args.num_layers:
    type: choice
    values: [1, 2, 3, 4, 5]

  model.init_args.d_model:
    type: choice
    values: [64, 128, 256, 512]

  data.init_args.seq_len:
    type: choice
    values: [100, 200, 300, 400, 500]

  model.init_args.criterion.init_args.quantiles:
    type: choice
    values:
      # 3 quantiles
      - [0.25, 0.5, 0.75]
      - [0.1, 0.5, 0.9]
      # 5 quantiles
      - [0.1, 0.25, 0.5, 0.75, 0.9]
      - [0.05, 0.25, 0.5, 0.75, 0.95]
      # 15 quantiles
      - [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]

  data.init_args.downsample:
    type: choice
    values: [10, 20, 40, 50, 60, 80, 100]

  optimizer.init_args.lr:
    type: loguniform
    min: 1.e-5
    max: 1.e-2

# Tune execution settings
tune_config:
  num_samples: 50

  # Primary metric for optimization
  metric: "RMSE/validation/dataloader_idx_0"
  mode: min

  # Additional metrics to log
  logging_metrics:
    - "MSE/validation/dataloader_idx_0"
    - "SMAPE/validation/dataloader_idx_0"
    - "loss/train"
    - "loss/validation/dataloader_idx_0"

  scheduler:
    type: asha
    max_t: 100
    grace_period: 10
    reduction_factor: 2

  search_algorithm:
    type: hyperopt

  resources:
    cpu: 1
    gpu: 0.25

  experiment_name: "lstm_hyperopt"
  storage_path: "/tmp/ray_results"
